---
layout: post
title:      "How a Social Scientist Turned to Data Science"
date:       2020-07-08 09:19:37 -0400
permalink:  how_a_social_scientist_turned_to_data_science
---

As an undergraduate, I hated math. I dabbled in every discipline that fell within or adjacent to social science: political theory, sociology, psychology, environmental studies, legal studies, and history, while avoiding math in all but a few courses. It wasn’t until I dove more deeply into statistics as a political science master’s student that I had even heard of the field of data science. In grad school, we learned how to compare country-level data, analyze the results of polls and social surveys, and a bit about how to code in R—which I later discovered doesn't even scratch the surface of how data analytics and data science has informed politically consequential decisions. My original aversion to mathematics and computing ran deeper than mere distaste. I viewed math's encroachment into political science as incompatible with the creative and imaginative thinking that I have always understood to be at the core of participatory, democratic politics. If we believe that influencing voting behavior, for instance, is reducible to a fixed set of inputs and outputs, will this come at a cost for our ability to engage voters organically? If the value of a public service is likewise weighed only by its calculable, instrumental outcomes, what role is left for the human heart and mind to reflect on that value? As a former teacher, I know all too well that when high-stakes decisions are driven by data alone—absent of any qualitative reflection—then existing inequities may be uncritically reinforced. 

If there is any skill that social scientists can be said to exercise exceptionally well, it is the ability to think critically: to not take anything that human beings do for granted, but to instead endlessly ask *why* and *for whom* we do it. These questions, unfortunately, have not been centered in many of the applications of data science methods to politics and public policy. It is for this reason that data science may stand to benefit from a broader presence of social scientists in the field—and why I have developed an interest in how a passion for data and its power can be dovetailed with a love for humanity. We should regard with necessary suspicion any insistence to "let the data speak" that does not also elevate the voices of human beings who are affected by data collection, analysis, and the deployment of data-driven tools in the public realm. 

Some mathematicians have already written extensively on what can go wrong when we seek to address problems with math alone, while failing to look holistically at its social and political consequences. One notable example of such a critique is *Weapons of Math Destruction* by data scientist Cathy O'Neill. In this book, O'Neill explores how big data has been weaponized to systematically deny people access to health insurance, credit, employment and education. One chapter addresses the use of big data in the criminal justice system, with a particular focus on crime prediction models like PredPol. These models use data on the locations where past arrests have been made to predict where the next crime will occur, and influence police patrolling accordingly. If a given police department has targeted low-income Black communities for arrests in the past, then most crime prediction models will point the department to those same communities to intervene in future crime. Such models “codify the past,” and if the past is something that we don’t want to reproduce, then it’s time to get to work on something with a more hopeful promise. The recent murders of George Floyd, Breonna Taylor, Ahmaud Arbery, and countless others—and the consequent surge of protests against police racial violence—has only deepened our understanding that more policing will not serve as a solution to any of the problems our communities are facing.

Does that mean that data-driven models can play no role in fostering safer, more just and more equitable communities? No. It means, rather, that we need to engage more substantively with the question of whom a given model serves, and be willing to abandon those models that may threaten democracy and justice. If a crime prediction model serves mainly to make a cop’s job easier and to remove personal accountability for racial violence, then it should probably be discarded. Crime prediction is just one of many contexts in which the misuse of data science tools has had disasterous consequences for society. But I'd like to believe that it doesn't have to be that way. 

> “With most weapons of math destruction, the heart of the problem is almost always the objective. Change the objective from leeching off people to helping them, and a WMD is disarmed—and can even become a force for good.” -O'Neill 

Whether you are a seasoned data scientist or someone who is just entering the field, we have a responsibility to critically examine our objectives and ask whether they are in service of the world we want to create. I'm excited to continue grappling with this task, and hope that others—at whatever stage in their data science journey they may be—will join me.

